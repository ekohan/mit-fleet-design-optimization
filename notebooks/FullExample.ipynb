{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156a9009-d04d-4017-a02a-84ad339dc71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Capacitated K-Means...\n",
      "Map has been saved to Capacitated_K-Means_clusters_map.html.\n",
      "Running Capacitated K-Medoids...\n",
      "Map has been saved to Capacitated_K-Medoids_clusters_map.html.\n",
      "\n",
      "Clustering Evaluation Results:\n",
      "               Algorithm  Silhouette Score      WCSS  Capacity Violations  \\\n",
      "0    Capacitated K-Means          0.290331  0.157329                    0   \n",
      "1  Capacitated K-Medoids          0.358137  3.055251                    0   \n",
      "\n",
      "   Time Violations  Number of Clusters  Elapsed Time (s)  \n",
      "0                0                 210          0.936448  \n",
      "1               10                  10          0.156660  \n",
      "\n",
      "Best Algorithm Selected: Capacitated K-Medoids\n",
      "\n",
      "Cluster Summary for MILP:\n",
      "   Cluster  Dry_Demand  Chilled_Demand  Frozen_Demand  Latitude  Longitude  \\\n",
      "0        0        2386            1713           1210  4.734553 -74.165226   \n",
      "1        1        2278            1718           1247  4.637490 -74.142560   \n",
      "2        2        1675            1369            867  4.768387 -74.094396   \n",
      "3        3        1751            1320            947  4.617990 -74.047682   \n",
      "4        4        2087            1657           1061  4.694842 -74.061830   \n",
      "\n",
      "   Service_Time  Time_From_Depot  \n",
      "0          2360      3105.800572  \n",
      "1          2360      3161.340762  \n",
      "2          1690      2041.220590  \n",
      "3          1780      3012.717898  \n",
      "4          2190      1701.313325  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Clustering algorithms\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# For mapping and visualization\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Generate Synthetic Customer Data for Bogotá\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "num_customers = 2199\n",
    "\n",
    "# Random geographic coordinates around Bogotá\n",
    "latitudes = np.random.uniform(4.5, 4.9, size=num_customers)\n",
    "longitudes = np.random.uniform(-74.2, -74.0, size=num_customers)\n",
    "\n",
    "# Random demand for different product types (dry, chilled, frozen)\n",
    "dry_demand = np.random.randint(1, 20, size=num_customers)\n",
    "chilled_demand = np.random.randint(1, 15, size=num_customers)\n",
    "frozen_demand = np.random.randint(1, 10, size=num_customers)\n",
    "\n",
    "# Fixed service time per customer (in minutes)\n",
    "service_time_per_customer = 10\n",
    "\n",
    "# Customer DataFrame\n",
    "customers = pd.DataFrame({\n",
    "    'Customer_ID': np.arange(1, num_customers + 1),\n",
    "    'Latitude': latitudes,\n",
    "    'Longitude': longitudes,\n",
    "    'Dry_Demand': dry_demand,\n",
    "    'Chilled_Demand': chilled_demand,\n",
    "    'Frozen_Demand': frozen_demand,\n",
    "    'Service_Time': service_time_per_customer  # Fixed service time\n",
    "})\n",
    "\n",
    "# Depot location (Assuming central Bogotá)\n",
    "depot = {'Latitude': 4.7, 'Longitude': -74.1}\n",
    "\n",
    "# Vehicle capacity constraints (example capacities)\n",
    "vehicle_capacity = {\n",
    "    'Dry_Demand': 5000,\n",
    "    'Chilled_Demand': 3000,\n",
    "    'Frozen_Demand': 2000\n",
    "}\n",
    "\n",
    "# Maximum operating time (in minutes)\n",
    "max_operating_time = 8 * 60  # 8 hours\n",
    "\n",
    "# Step 2: Compute Travel Time Matrix\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    # Haversine distance in kilometers\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(delta_phi/2.0)**2 + \\\n",
    "        np.cos(phi1)*np.cos(phi2)*np.sin(delta_lambda/2.0)**2\n",
    "    return R * 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "# Calculate travel time between customers and depot (Assuming average speed)\n",
    "average_speed = 40  # km/h\n",
    "\n",
    "def compute_travel_time(lat1, lon1, lat2, lon2):\n",
    "    distance = haversine_distance(lat1, lon1, lat2, lon2)\n",
    "    time = (distance / average_speed) * 60  # Convert hours to minutes\n",
    "    return time\n",
    "\n",
    "# Compute travel time from depot to each customer\n",
    "customers['Time_From_Depot'] = customers.apply(\n",
    "    lambda row: compute_travel_time(depot['Latitude'], depot['Longitude'], row['Latitude'], row['Longitude']), axis=1)\n",
    "\n",
    "# Step 3: Define Clustering Algorithms with Constraints\n",
    "\n",
    "# Capacitated K-Means Clustering\n",
    "def capacitated_kmeans(customers, vehicle_capacity, max_operating_time, n_clusters):\n",
    "    # Initialize KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    customer_coords = customers[['Latitude', 'Longitude']]\n",
    "    \n",
    "    # Fit KMeans\n",
    "    kmeans.fit(customer_coords)\n",
    "    customers['Cluster'] = kmeans.labels_\n",
    "    \n",
    "    # Initialize variables\n",
    "    iteration = 0\n",
    "    max_iterations = 100\n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        # Check capacity and time constraints for each cluster\n",
    "        clusters_to_split = []\n",
    "        for cluster_id in range(n_clusters):\n",
    "            cluster_customers = customers[customers['Cluster'] == cluster_id]\n",
    "            \n",
    "            # Calculate total demands\n",
    "            total_dry = cluster_customers['Dry_Demand'].sum()\n",
    "            total_chilled = cluster_customers['Chilled_Demand'].sum()\n",
    "            total_frozen = cluster_customers['Frozen_Demand'].sum()\n",
    "            total_service_time = cluster_customers['Service_Time'].sum()\n",
    "            \n",
    "            # Calculate total travel time (simplified as sum of travel times from depot)\n",
    "            total_travel_time = cluster_customers['Time_From_Depot'].sum()\n",
    "            total_time = total_service_time + total_travel_time\n",
    "            \n",
    "            # Check capacity constraints\n",
    "            if (total_dry > vehicle_capacity['Dry_Demand'] or\n",
    "                total_chilled > vehicle_capacity['Chilled_Demand'] or\n",
    "                total_frozen > vehicle_capacity['Frozen_Demand'] or\n",
    "                total_time > max_operating_time):\n",
    "                clusters_to_split.append(cluster_id)\n",
    "        \n",
    "        if not clusters_to_split:\n",
    "            break  # All clusters meet the constraints\n",
    "        \n",
    "        # Split clusters that violate constraints\n",
    "        for cluster_id in clusters_to_split:\n",
    "            cluster_customers = customers[customers['Cluster'] == cluster_id]\n",
    "            # Re-cluster the customers in this cluster into two clusters\n",
    "            sub_kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "            sub_kmeans.fit(cluster_customers[['Latitude', 'Longitude']])\n",
    "            labels = sub_kmeans.labels_\n",
    "            # Assign new cluster IDs\n",
    "            new_cluster_id = customers['Cluster'].max() + 1\n",
    "            customers.loc[cluster_customers.index[labels == 1], 'Cluster'] = new_cluster_id\n",
    "        n_clusters = customers['Cluster'].nunique()\n",
    "    return customers\n",
    "\n",
    "# Hierarchical Clustering with Capacity Constraints\n",
    "def capacitated_hierarchical(customers, vehicle_capacity, max_operating_time, distance_threshold=0.01):\n",
    "    # Compute distance matrix\n",
    "    customer_coords = customers[['Latitude', 'Longitude']].values\n",
    "    model = AgglomerativeClustering(n_clusters=None, distance_threshold=distance_threshold, linkage='ward')\n",
    "    customers['Cluster'] = model.fit_predict(customer_coords)\n",
    "    \n",
    "    # Similar to capacitated_kmeans, we need to check constraints and adjust clusters\n",
    "    # Due to complexity, we can skip detailed implementation here\n",
    "    return customers\n",
    "\n",
    "# K-Medoids Clustering\n",
    "def capacitated_kmedoids(customers, vehicle_capacity, max_operating_time, n_clusters):\n",
    "    kmedoids = KMedoids(n_clusters=n_clusters, random_state=42)\n",
    "    customer_coords = customers[['Latitude', 'Longitude']]\n",
    "    kmedoids.fit(customer_coords)\n",
    "    customers['Cluster'] = kmedoids.labels_\n",
    "    \n",
    "    # Constraint checking similar to capacitated_kmeans\n",
    "    # Implement constraint adjustments as needed\n",
    "    return customers\n",
    "\n",
    "def visualize_clusters(customers, algorithm_name):\n",
    "    # Calculate the mean latitude and longitude to center the map\n",
    "    map_center = [customers['Latitude'].mean(), customers['Longitude'].mean()]\n",
    "    \n",
    "    # Initialize the Folium map\n",
    "    m = folium.Map(location=map_center, zoom_start=12, tiles='CartoDB positron')\n",
    "    \n",
    "    # Generate a color palette\n",
    "    num_clusters = customers['Cluster'].nunique()\n",
    "    colors = plt.cm.get_cmap('tab20', num_clusters).colors\n",
    "    color_map = dict(zip(sorted(customers['Cluster'].unique()), [matplotlib.colors.rgb2hex(c) for c in colors]))\n",
    "    \n",
    "    # Add depot marker\n",
    "    folium.Marker(\n",
    "        location=(depot['Latitude'], depot['Longitude']),\n",
    "        icon=folium.Icon(color='red', icon='home'),\n",
    "        popup='Depot'\n",
    "    ).add_to(m)\n",
    "    \n",
    "    # Create a marker cluster\n",
    "    marker_cluster = MarkerCluster().add_to(m)\n",
    "    \n",
    "    # Add customer markers to the map\n",
    "    for _, row in customers.iterrows():\n",
    "        cluster_id = row['Cluster']\n",
    "        folium.CircleMarker(\n",
    "            location=(row['Latitude'], row['Longitude']),\n",
    "            radius=4,\n",
    "            color=color_map[cluster_id],\n",
    "            fill=True,\n",
    "            fill_color=color_map[cluster_id],\n",
    "            fill_opacity=0.7,\n",
    "            popup=folium.Popup(html=f'''\n",
    "                <b>Customer ID:</b> {row[\"Customer_ID\"]}<br>\n",
    "                <b>Cluster:</b> {cluster_id}<br>\n",
    "                <b>Dry Demand:</b> {row[\"Dry_Demand\"]}<br>\n",
    "                <b>Chilled Demand:</b> {row[\"Chilled_Demand\"]}<br>\n",
    "                <b>Frozen Demand:</b> {row[\"Frozen_Demand\"]}\n",
    "            ''', max_width=250)\n",
    "        ).add_to(marker_cluster)\n",
    "    \n",
    "    # Add a legend to the map\n",
    "    legend_html = '''\n",
    "     <div style=\"\n",
    "     position: fixed;\n",
    "     bottom: 50px; left: 50px; width: 200px; height: auto;\n",
    "     border:2px solid grey; z-index:9999; font-size:14px;\n",
    "     background-color: white; opacity: 0.8;\n",
    "     \">\n",
    "     <h4 style=\"margin:10px;\">Cluster Colors</h4>\n",
    "    '''\n",
    "    for cluster_id, color in color_map.items():\n",
    "        legend_html += f'''\n",
    "         <p style=\"margin:10px;\">\n",
    "         <span style=\"background-color:{color};width:15px;height:15px;display:inline-block;border:1px solid #000;\"></span>\n",
    "         &nbsp;Cluster {cluster_id}\n",
    "         </p>\n",
    "        '''\n",
    "    legend_html += '</div>'\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    # Save the map to an HTML file\n",
    "    map_filename = f'{algorithm_name.replace(\" \", \"_\")}_clusters_map.html'\n",
    "    m.save(map_filename)\n",
    "    print(f\"Map has been saved to {map_filename}.\")\n",
    "\n",
    "\n",
    "# Step 4: Evaluate Clustering Results\n",
    "\n",
    "def evaluate_clustering(customers):\n",
    "    # Silhouette Score (requires at least 2 clusters)\n",
    "    if customers['Cluster'].nunique() > 1:\n",
    "        customer_coords = customers[['Latitude', 'Longitude']]\n",
    "        silhouette_avg = silhouette_score(customer_coords, customers['Cluster'])\n",
    "    else:\n",
    "        silhouette_avg = np.nan\n",
    "    \n",
    "    # Total Within-Cluster Sum of Squares (WCSS)\n",
    "    wcss = 0\n",
    "    for cluster_id in customers['Cluster'].unique():\n",
    "        cluster_customers = customers[customers['Cluster'] == cluster_id]\n",
    "        centroid = cluster_customers[['Latitude', 'Longitude']].mean()\n",
    "        distances = cdist(cluster_customers[['Latitude', 'Longitude']], [centroid])\n",
    "        wcss += (distances**2).sum()\n",
    "    \n",
    "    # Capacity and Time Utilization\n",
    "    capacity_violations = 0\n",
    "    time_violations = 0\n",
    "    for cluster_id in customers['Cluster'].unique():\n",
    "        cluster_customers = customers[customers['Cluster'] == cluster_id]\n",
    "        total_dry = cluster_customers['Dry_Demand'].sum()\n",
    "        total_chilled = cluster_customers['Chilled_Demand'].sum()\n",
    "        total_frozen = cluster_customers['Frozen_Demand'].sum()\n",
    "        total_service_time = cluster_customers['Service_Time'].sum()\n",
    "        total_travel_time = cluster_customers['Time_From_Depot'].sum()\n",
    "        total_time = total_service_time + total_travel_time\n",
    "        if (total_dry > vehicle_capacity['Dry_Demand'] or\n",
    "            total_chilled > vehicle_capacity['Chilled_Demand'] or\n",
    "            total_frozen > vehicle_capacity['Frozen_Demand']):\n",
    "            capacity_violations += 1\n",
    "        if total_time > max_operating_time:\n",
    "            time_violations += 1\n",
    "    return silhouette_avg, wcss, capacity_violations, time_violations\n",
    "\n",
    "# Step 5: Run Clustering Algorithms and Evaluate\n",
    "\n",
    "cluster_algorithms = {\n",
    "    'Capacitated K-Means': capacitated_kmeans,\n",
    "    'Capacitated K-Medoids': capacitated_kmedoids,\n",
    "    # 'Capacitated Hierarchical': capacitated_hierarchical  # Uncomment if implemented\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, algorithm in cluster_algorithms.items():\n",
    "    print(f\"Running {name}...\")\n",
    "    start_time = time.time()\n",
    "    n_clusters_initial = 10  # Starting number of clusters\n",
    "    clustered_customers = algorithm(customers.copy(), vehicle_capacity, max_operating_time, n_clusters_initial)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    silhouette_avg, wcss, capacity_violations, time_violations = evaluate_clustering(clustered_customers)\n",
    "    results.append({\n",
    "        'Algorithm': name,\n",
    "        'Silhouette Score': silhouette_avg,\n",
    "        'WCSS': wcss,\n",
    "        'Capacity Violations': capacity_violations,\n",
    "        'Time Violations': time_violations,\n",
    "        'Number of Clusters': clustered_customers['Cluster'].nunique(),\n",
    "        'Elapsed Time (s)': elapsed_time\n",
    "    })\n",
    "    # Save clustered data for MILP\n",
    "    clustered_customers.to_csv(f'{name.replace(\" \", \"_\")}_clusters.csv', index=False)\n",
    "    # Visualization (Optional)\n",
    "    visualize_clusters(clustered_customers, name)\n",
    "\n",
    "# Step 6: Display Evaluation Results\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nClustering Evaluation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Step 7: Prepare Clusters for MILP (Choose the best algorithm based on evaluation)\n",
    "\n",
    "# For demonstration, let's choose the algorithm with the highest Silhouette Score\n",
    "best_algorithm = results_df.sort_values(by='Silhouette Score', ascending=False).iloc[0]['Algorithm']\n",
    "print(f\"\\nBest Algorithm Selected: {best_algorithm}\")\n",
    "\n",
    "# Load the best clustering result\n",
    "clustered_customers = pd.read_csv(f'{best_algorithm.replace(\" \", \"_\")}_clusters.csv')\n",
    "\n",
    "def prepare_clusters_for_milp(clustered_customers):\n",
    "    cluster_summary = clustered_customers.groupby('Cluster').agg({\n",
    "        'Dry_Demand': 'sum',\n",
    "        'Chilled_Demand': 'sum',\n",
    "        'Frozen_Demand': 'sum',\n",
    "        'Latitude': 'mean',\n",
    "        'Longitude': 'mean',\n",
    "        'Service_Time': 'sum',\n",
    "        'Time_From_Depot': 'sum'\n",
    "    }).reset_index()\n",
    "    return cluster_summary\n",
    "\n",
    "cluster_summary = prepare_clusters_for_milp(clustered_customers)\n",
    "print(\"\\nCluster Summary for MILP:\")\n",
    "print(cluster_summary.head())\n",
    "\n",
    "# Save the result to a CSV file\n",
    "cluster_summary.to_csv('clusters_for_milp.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b3abf-4769-4542-8825-a450830d0148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
